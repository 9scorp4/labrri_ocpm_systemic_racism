2024-07-02 17:28:35,792:INFO:Initializing Tools
2024-07-02 17:28:35,793:INFO:Added 102 additional stopwords
2024-07-02 17:28:36,972:INFO:Initializing Process
2024-07-02 17:28:36,972:INFO:Initializing Tools
2024-07-02 17:28:36,973:INFO:Added 102 additional stopwords
2024-07-02 17:28:37,583:INFO:Added 102 additional stopwords
2024-07-02 17:28:38,371:DEBUG:Processing sentence:
data\data\8.4-Diversité artistique
2024-07-02 17:28:38,371:DEBUG:Sentence loadad!
2024-07-02 17:28:38,371:DEBUG:Tokenizing...
2024-07-02 17:28:38,374:DEBUG:Tokens before lemmatization:
['data\\data\\8.4-Diversité', 'artistique']
2024-07-02 17:28:38,376:DEBUG:Lemmatizing...
2024-07-02 17:28:38,383:DEBUG:Lemmatized sentence:
[{'fr': 'data\\data\\8.4-diversité', 'en': ''}, {'fr': 'artistique', 'en': ''}]
2024-07-02 17:28:38,383:DEBUG:Total tokens: 2
2024-07-02 17:28:38,383:DEBUG:Processed sentence:
[{'fr': 'data\\data\\8.4-diversité', 'en': ''}, {'fr': 'artistique', 'en': ''}]
2024-07-02 17:28:38,383:DEBUG:Processing sentence:
Montréal (DAM)\8.4_dam.pdf
2024-07-02 17:28:38,383:DEBUG:Sentence loadad!
2024-07-02 17:28:38,383:DEBUG:Tokenizing...
2024-07-02 17:28:38,386:DEBUG:Tokens before lemmatization:
['Montréal', '(', 'DAM)\\8.4_dam.pdf']
2024-07-02 17:28:38,386:DEBUG:Lemmatizing...
2024-07-02 17:28:38,395:DEBUG:Lemmatized sentence:
[{'fr': 'Montréal', 'en': ''}, {'fr': '(', 'en': ''}, {'fr': 'dam)\\8.4_dam.pdf', 'en': ''}]
2024-07-02 17:28:38,395:DEBUG:Total tokens: 3
2024-07-02 17:28:38,395:DEBUG:Processed sentence:
[{'fr': 'Montréal', 'en': ''}, {'fr': '(', 'en': ''}, {'fr': 'dam)\\8.4_dam.pdf', 'en': ''}]
2024-07-02 17:28:38,395:DEBUG:Document processed successfully!
2024-07-02 17:28:38,526:INFO:Added 247 additional stopwords
2024-07-02 17:28:38,526:DEBUG:Cleaning 1 documents
2024-07-02 17:28:38,526:DEBUG:Cleaning 1 documents
2024-07-02 17:28:38,526:ERROR:Failed to clean documents. Error: sequence item 0: expected str instance, list found
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\noise_remover.py", line 181, in fr_docs
    doc = " ".join(doc)
          ^^^^^^^^^^^^^
TypeError: sequence item 0: expected str instance, list found
2024-07-02 17:28:38,526:DEBUG:Starting analysis for fr with sentences: []
2024-07-02 17:28:38,526:DEBUG:Starting analysis for fr with sentences: []
2024-07-02 17:28:38,526:ERROR:Failed to analyze document. Error: docs cannot be None
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\analysis.py", line 245, in doc_single
    results = doc_analyzer.analyze({self.lang: cleaned_doc})
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 230, in analyze
    self.analyze_lang(lang_sentences, self.lang)
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 170, in analyze_lang
    tfidf_matrix = self.vectorize(sentences)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 52, in vectorize
    raise ValueError("docs cannot be None")
ValueError: docs cannot be None
2024-07-02 17:28:38,527:ERROR:Failed to process data. Error: docs cannot be None
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis_main.py", line 32, in main
    results = analysis.doc_single(document)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\analysis.py", line 245, in doc_single
    results = doc_analyzer.analyze({self.lang: cleaned_doc})
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 230, in analyze
    self.analyze_lang(lang_sentences, self.lang)
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 170, in analyze_lang
    tfidf_matrix = self.vectorize(sentences)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 52, in vectorize
    raise ValueError("docs cannot be None")
ValueError: docs cannot be None
