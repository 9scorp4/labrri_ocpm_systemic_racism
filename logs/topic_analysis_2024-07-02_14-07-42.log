2024-07-02 14:07:48,789:INFO:Initializing Tools
2024-07-02 14:07:48,791:INFO:Added 102 additional stopwords
2024-07-02 14:07:50,793:INFO:Initializing Process
2024-07-02 14:07:50,793:INFO:Initializing Tools
2024-07-02 14:07:50,794:INFO:Added 102 additional stopwords
2024-07-02 14:07:52,582:INFO:Added 102 additional stopwords
2024-07-02 14:07:53,734:DEBUG:Processing sentence:
data\data\8.4-Diversité artistique
2024-07-02 14:07:53,734:DEBUG:Sentence loadad!
2024-07-02 14:07:53,734:DEBUG:Tokenizing...
2024-07-02 14:07:53,734:ERROR:Failed to tokenize. Error: 'dict' object is not callable
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\text_processing.py", line 42, in single_sentence
    doc = self.nlp(text)
          ^^^^^^^^^^^^^^
TypeError: 'dict' object is not callable
2024-07-02 14:07:53,736:DEBUG:Processing sentence:
Montréal (DAM)\8.4_dam.pdf
2024-07-02 14:07:53,737:DEBUG:Sentence loadad!
2024-07-02 14:07:53,737:DEBUG:Tokenizing...
2024-07-02 14:07:53,737:ERROR:Failed to tokenize. Error: 'dict' object is not callable
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\text_processing.py", line 42, in single_sentence
    doc = self.nlp(text)
          ^^^^^^^^^^^^^^
TypeError: 'dict' object is not callable
2024-07-02 14:07:53,737:DEBUG:Processing sentence:
data\data\8.4-Diversité artistique Montréal (DAM)\8.4_dam.pdf
2024-07-02 14:07:53,737:DEBUG:Sentence loadad!
2024-07-02 14:07:53,737:DEBUG:Tokenizing...
2024-07-02 14:07:53,737:ERROR:Failed to tokenize. Error: 'dict' object is not callable
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\text_processing.py", line 42, in single_sentence
    doc = self.nlp(text)
          ^^^^^^^^^^^^^^
TypeError: 'dict' object is not callable
2024-07-02 14:07:53,737:DEBUG:Document processed successfully!
2024-07-02 14:07:53,833:INFO:Added 2 additional stopwords
2024-07-02 14:07:53,833:DEBUG:Cleaning 1 documents
2024-07-02 14:07:53,833:INFO:Cleaning bilingual documents
2024-07-02 14:07:53,833:DEBUG:Documents to clean: 1
2024-07-02 14:07:53,833:DEBUG:Flattened documents: 0
2024-07-02 14:07:53,833:DEBUG:Merged documents: {'fr': [], 'en': []}
2024-07-02 14:07:53,833:DEBUG:Translated punctuation: {'fr': [], 'en': []}
2024-07-02 14:07:53,833:DEBUG:Filtered empty strings: {'fr': [], 'en': []}
2024-07-02 14:07:53,833:DEBUG:Filtered stopwords: {'fr': [], 'en': []}
2024-07-02 14:07:53,834:DEBUG:Removed duplicates: {'fr': [], 'en': []}
2024-07-02 14:07:53,834:INFO:Documents cleaned successfully!
2024-07-02 14:07:53,834:DEBUG:Starting analysis for fr with sentences: []
2024-07-02 14:07:53,834:DEBUG:Vectorizing 0 documents
2024-07-02 14:07:53,834:ERROR:Failed to vectorize. Error: empty vocabulary; perhaps the documents only contain stop words
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 59, in vectorize
    tfidf_matrix = self.vectorizer.fit_transform(docs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\feature_extraction\text.py", line 2138, in fit_transform
    X = super().fit_transform(raw_documents)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\feature_extraction\text.py", line 1389, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\feature_extraction\text.py", line 1295, in _count_vocab
    raise ValueError(
ValueError: empty vocabulary; perhaps the documents only contain stop words
2024-07-02 14:07:53,846:ERROR:Failed to analyze document. Error: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\analysis.py", line 243, in doc_single
    results = doc_analyzer.analyze({'fr': cleaned_doc.get('fr', []), 'en': cleaned_doc.get('en', [])})
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 199, in analyze
    self.analyze_lang(lang_sentences, 'fr')
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 162, in analyze_lang
    if tfidf_matrix.shape[0] == 0:
       ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
2024-07-02 14:07:53,847:ERROR:Failed to process data. Error: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis_main.py", line 32, in main
    results = analysis.doc_single(document)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\analysis.py", line 243, in doc_single
    results = doc_analyzer.analyze({'fr': cleaned_doc.get('fr', []), 'en': cleaned_doc.get('en', [])})
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 199, in analyze
    self.analyze_lang(lang_sentences, 'fr')
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 162, in analyze_lang
    if tfidf_matrix.shape[0] == 0:
       ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
2024-07-02 14:08:06,563:INFO:Initializing Tools
2024-07-02 14:08:06,564:INFO:Added 102 additional stopwords
2024-07-02 14:08:07,748:INFO:Initializing Process
2024-07-02 14:08:07,748:INFO:Initializing Tools
2024-07-02 14:08:07,749:INFO:Added 102 additional stopwords
2024-07-02 14:08:08,308:INFO:Added 102 additional stopwords
2024-07-02 14:08:08,905:DEBUG:Processing sentence:
data\data\8.4-Diversité artistique
2024-07-02 14:08:08,905:DEBUG:Sentence loadad!
2024-07-02 14:08:08,905:DEBUG:Tokenizing...
2024-07-02 14:08:08,909:DEBUG:Tokens before lemmatization:
['data\\data\\8.4-Diversité', 'artistique']
2024-07-02 14:08:08,909:DEBUG:Lemmatizing...
2024-07-02 14:08:08,917:DEBUG:Lemmatized sentence:
[{'fr': 'data\\data\\8.4-diversité', 'en': ''}, {'fr': 'artistique', 'en': ''}]
2024-07-02 14:08:08,917:DEBUG:Total tokens: 2
2024-07-02 14:08:08,917:DEBUG:Processed sentence:
[{'fr': 'data\\data\\8.4-diversité', 'en': ''}, {'fr': 'artistique', 'en': ''}]
2024-07-02 14:08:08,917:DEBUG:Processing sentence:
Montréal (DAM)\8.4_dam.pdf
2024-07-02 14:08:08,917:DEBUG:Sentence loadad!
2024-07-02 14:08:08,917:DEBUG:Tokenizing...
2024-07-02 14:08:08,921:DEBUG:Tokens before lemmatization:
['Montréal', '(', 'DAM)\\8.4_dam.pdf']
2024-07-02 14:08:08,921:DEBUG:Lemmatizing...
2024-07-02 14:08:08,929:DEBUG:Lemmatized sentence:
[{'fr': 'Montréal', 'en': ''}, {'fr': '(', 'en': ''}, {'fr': 'dam)\\8.4_dam.pdf', 'en': ''}]
2024-07-02 14:08:08,929:DEBUG:Total tokens: 3
2024-07-02 14:08:08,930:DEBUG:Processed sentence:
[{'fr': 'Montréal', 'en': ''}, {'fr': '(', 'en': ''}, {'fr': 'dam)\\8.4_dam.pdf', 'en': ''}]
2024-07-02 14:08:08,930:DEBUG:Document processed successfully!
2024-07-02 14:08:09,026:INFO:Added 247 additional stopwords
2024-07-02 14:08:09,026:DEBUG:Cleaning 1 documents
2024-07-02 14:08:09,026:DEBUG:Cleaning 1 documents
2024-07-02 14:08:09,026:ERROR:Failed to clean documents. Error: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'list'>
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\noise_remover.py", line 176, in fr_docs
    tokens = self.nlp_fr(doc)
             ^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\spacy\language.py", line 1037, in __call__
    doc = self._ensure_doc(text)
          ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\spacy\language.py", line 1131, in _ensure_doc
    raise ValueError(Errors.E1041.format(type=type(doc_like)))
ValueError: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'list'>
2024-07-02 14:08:09,034:DEBUG:Starting analysis for fr with sentences: []
2024-07-02 14:08:09,035:DEBUG:Starting analysis for fr with sentences: []
2024-07-02 14:08:09,035:DEBUG:Vectorizing 0 documents
2024-07-02 14:08:09,035:ERROR:Failed to vectorize. Error: empty vocabulary; perhaps the documents only contain stop words
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 59, in vectorize
    tfidf_matrix = self.vectorizer.fit_transform(docs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\feature_extraction\text.py", line 2138, in fit_transform
    X = super().fit_transform(raw_documents)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\feature_extraction\text.py", line 1389, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\.conda\Lib\site-packages\sklearn\feature_extraction\text.py", line 1295, in _count_vocab
    raise ValueError(
ValueError: empty vocabulary; perhaps the documents only contain stop words
2024-07-02 14:08:09,035:ERROR:Failed to analyze document. Error: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\analysis.py", line 245, in doc_single
    results = doc_analyzer.analyze({self.lang: cleaned_doc})
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 219, in analyze
    self.analyze_lang(lang_sentences, self.lang)
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 162, in analyze_lang
    if tfidf_matrix.shape[0] == 0:
       ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
2024-07-02 14:08:09,036:ERROR:Failed to process data. Error: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis_main.py", line 32, in main
    results = analysis.doc_single(document)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\analysis.py", line 245, in doc_single
    results = doc_analyzer.analyze({self.lang: cleaned_doc})
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 219, in analyze
    self.analyze_lang(lang_sentences, self.lang)
  File "c:\Users\nicol\Documents\UdeM\Maîtrise\Données\labrri_ocpm_systemic_racism\scripts\topic_analysis\documents.py", line 162, in analyze_lang
    if tfidf_matrix.shape[0] == 0:
       ^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
